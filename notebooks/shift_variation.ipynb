{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from data.input_data import DatasetCreator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the absolute path of the current file\n",
    "current_file_path = Path('decision_boundary.ipynb').resolve()\n",
    "\n",
    "# Get the directory of the current file\n",
    "project_dir = current_file_path.parent\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "sys.path.insert(0, str(project_dir))\n",
    "\n",
    "# Step 1: Create Datasets\n",
    "dataset_creator = DatasetCreator()\n",
    "blob_dataset = dataset_creator.create_blob_dataset()\n",
    "circles_dataset = dataset_creator.create_make_circles_dataset()\n",
    "\n",
    "# Step 2: Split Data into Training, Validation, and Test Sets\n",
    "X_blob, y_blob = blob_dataset['X'], blob_dataset['y']\n",
    "X_circles, y_circles = circles_dataset['X'], circles_dataset['y']\n",
    "\n",
    "# Split blob dataset into training and temporary (remaining) data\n",
    "X_blob_train_temp, X_blob_test, y_blob_train_temp, y_blob_test = train_test_split(X_blob, y_blob, test_size=0.2,\n",
    "                                                                                  random_state=42)\n",
    "X_blob_train, X_blob_val, y_blob_train, y_blob_val = train_test_split(X_blob_train_temp, y_blob_train_temp,\n",
    "                                                                      test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Blob Dataset:\")\n",
    "print(f\"Train set: {X_blob_train.shape}, Validation set: {X_blob_val.shape}, Test set: {X_blob_test.shape}\")\n",
    "\n",
    "# Split circles dataset into training and temporary (remaining) data\n",
    "X_circles_train_temp, X_circles_test, y_circles_train_temp, y_circles_test = train_test_split(X_circles, y_circles,\n",
    "                                                                                              test_size=0.2,\n",
    "                                                                                              random_state=42)\n",
    "X_circles_train, X_circles_val, y_circles_train, y_circles_val = train_test_split(X_circles_train_temp,\n",
    "                                                                                  y_circles_train_temp, test_size=0.25,\n",
    "                                                                                  random_state=42)\n",
    "\n",
    "print(f\"\\nCircles Dataset:\")\n",
    "print(f\"Train set: {X_circles_train.shape}, Validation set: {X_circles_val.shape}, Test set: {X_circles_test.shape}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To calculate the shift and variation for the basic model (SVM) and the ensemble model (Random Forest), we can use the concepts of bias and variance:\n",
    "\n",
    "1. **Shift (Bias)**: Bias measures how far off the predictions of a model are from the correct values on average.\n",
    "\n",
    "2. **Variation (Variance)**: Variance measures how much the predictions for a given point vary between different realizations of the model.\n",
    "\n",
    "Hereâ€™s how we can estimate these for our models:\n",
    "\n",
    "### Shift (Bias) Calculation:\n",
    "\n",
    "For bias estimation, we typically use the training error, assuming that the training set represents the true underlying distribution of the data. The bias can be approximated by the training error of the model.\n",
    "\n"
   ],
   "id": "c0453013f5eee8ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate bias (shift) for SVM and Random Forest\n",
    "svm_train_predictions = svm_model_blob.predict(X_blob_train)\n",
    "rf_train_predictions = rf_model_blob.predict(X_blob_train)\n",
    "\n",
    "svm_bias = mean_squared_error(y_blob_train, svm_train_predictions)\n",
    "rf_bias = mean_squared_error(y_blob_train, rf_train_predictions)\n",
    "\n",
    "print(f\"Shift (Bias) for SVM: {svm_bias:.4f}\")\n",
    "print(f\"Shift (Bias) for Random Forest: {rf_bias:.4f}\")\n",
    "\n",
    "\n",
    "### Variation (Variance) Calculation:\n",
    "\n",
    "# For variance estimation, we can use the difference between the training error and the test error, as the test error reflects the variability in performance due to different datasets.\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate variance (variation) for SVM and Random Forest\n",
    "svm_test_predictions = svm_model_blob.predict(X_blob_test)\n",
    "rf_test_predictions = rf_model_blob.predict(X_blob_test)\n",
    "\n",
    "svm_variance = mean_squared_error(y_blob_test, svm_test_predictions) - svm_bias\n",
    "rf_variance = mean_squared_error(y_blob_test, rf_test_predictions) - rf_bias\n",
    "\n",
    "print(f\"Variation (Variance) for SVM: {svm_variance:.4f}\")\n",
    "print(f\"Variation (Variance) for Random Forest: {rf_variance:.4f}\")\n"
   ],
   "id": "972e4011c517a35e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
